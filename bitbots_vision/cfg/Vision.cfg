#!/usr/bin/env python
PACKAGE = "bitbots_vision"

from dynamic_reconfigure.parameter_generator_catkin import *
import rospkg

rospack = rospkg.RosPack()
package_path = rospack.get_path('bitbots_vision')

gen = ParameterGenerator()

#########
# Enums #
#########

neural_network_type_enum = gen.enum(
  [
    gen.const("fcnn",str_t, "fcnn", "fcnn classifier"),
    gen.const("yolo_opencv",str_t, "yolo_opencv", "yolo object detection (opencv implementation)"),
    gen.const("yolo_darknet",str_t, "yolo_darknet", "yolo object detection (darknet implementation)"),
    gen.const("dummy",str_t, "dummy", "no balls will be detected")
  ],
  "An enum to set the ball classifier")

field_boundary_detector_enum = gen.enum(
  [
    gen.const("iteration",str_t, "iteration", "searches from the top until green"),
    gen.const("dynamic",str_t, "dynamic", "uses head_joint_state messages to switch between methods"),
    gen.const("reversed",str_t, "reversed", "searches from the bottom until white"),
    gen.const("cvreversed",str_t, "cvreversed", "searches from the bottom until white unsing opencv"),
    gen.const("binary",str_t, "binary", "uses binary search")
  ],
  "An enum to change the field_boundary finder method")

obstacle_detector_enum = gen.enum(
  [
    gen.const("convex",str_t, "convex", "finds obstacles using the difference of the convex and normal field boundary"),
    gen.const("distance",str_t, "distance", "parameters are adjusted for the height of the obstacle in the image and therefore its distance "),
    gen.const("step",str_t, "step", "finds obstacles using the height difference of the normal field boundary")
  ],
  "An enum to change the obstacle detector method")

# The following part creates dummy objects which are dynamicly replaced with the real enums if the vision starts.

field_color_space_enum = gen.enum([gen.const("dummy",str_t, "dummy", "dummy decription")], "Dummy")

dummy_list = ["dummy"]

fcnn_paths_enum = gen.enum([ gen.const("dummy",str_t, "dummy", "dummy decription")], "Dummy")
yolo_paths_enum = gen.enum([ gen.const("dummy",str_t, "dummy", "dummy decription")], "Dummy")

##########
# Groups #
##########

group_vision = gen.add_group("Vision", type="tab")
group_ROS = gen.add_group("ROS", type="tab")
group_neural_networks = gen.add_group("Neural Networks", type="tab")
group_color_detector = gen.add_group("Color", type="tab")
group_detector = gen.add_group("Detector", type="tab")

group_neural_network_type = group_detector.add_group("Ball", type="tab")
group_field_boundary_detector = group_detector.add_group("Field Boundary", type="tab")
group_line_detector = group_detector.add_group("Line", type="tab")
group_obstacle_detector = group_detector.add_group("Obstacle", type="tab")

group_field_color_detector = group_color_detector.add_group("Field")
group_white_color_detector = group_color_detector.add_group("White")
group_red_color_detector = group_color_detector.add_group("Red")
group_blue_color_detector = group_color_detector.add_group("Blue")

group_dynamic_color_space = group_field_color_detector.add_group("DynamicColorSpace")

group_fcnn = group_neural_networks.add_group("FCNN")
group_yolo = group_neural_networks.add_group("YOLO")

group_debug = group_vision.add_group("Debug")

##########
# Params #
##########

group_vision.add("vision_parallelize", bool_t, 0, "Run the neural net and the conventional part in parralel", None)
group_vision.add("vision_blind_threshold", int_t, 0, "Brightness theshold under which the vision thinks, that someone forgot the camera cap", min=0, max=765)

group_ROS.add("ROS_img_msg_topic", str_t, 0, "ROS topic of the image message", None)
group_ROS.add("ROS_img_msg_queue_size", int_t, 0, "ROS queue size for the image message", min=1, max=20)
group_ROS.add("ROS_fcnn_img_msg_topic", str_t, 0, "ROS topic of the fcnn output message", None)
group_ROS.add("ROS_field_boundary_msg_topic", str_t, 0, "ROS topic of the field boundary message", None)
group_ROS.add("ROS_ball_msg_topic", str_t, 0, "ROS topic of the ball message", None)
group_ROS.add("ROS_goal_parts_msg_topic", str_t, 0, "ROS topic of the goal parts message", None)
group_ROS.add("ROS_obstacle_msg_topic", str_t, 0, "ROS topic of the obstacles message", None)
group_ROS.add("ROS_line_msg_topic", str_t, 0, "ROS topic of the line message", None)
group_ROS.add("ROS_line_mask_msg_topic", str_t, 0, "ROS topic of the line mask message", None)
group_ROS.add("ROS_dynamic_color_space_msg_topic", str_t, 0, "ROS topic of the dynamic color space message", None)
group_ROS.add("ROS_debug_image_msg_topic", str_t, 0, "ROS topic of the debug image message", None)
group_ROS.add("ROS_debug_fcnn_image_msg_topic", str_t, 0, "ROS topic of the FCNN debug image message", None)
group_ROS.add("ROS_white_HSV_mask_image_msg_topic", str_t, 0, "ROS topic of the white HSV color detector mask debug image message", None)
group_ROS.add("ROS_red_HSV_mask_image_msg_topic", str_t, 0, "ROS topic of the red HSV color detector mask debug image message", None)
group_ROS.add("ROS_blue_HSV_mask_image_msg_topic", str_t, 0, "ROS topic of the blue HSV color detector mask debug image message", None)
group_ROS.add("ROS_field_mask_image_msg_topic", str_t, 0, "ROS topic of the field mask debug image message", None)
group_ROS.add("ROS_dynamic_color_space_field_mask_image_msg_topic", str_t, 0, "ROS topic of the dynamic color space field mask debug image message", None)

group_neural_networks.add("neural_network_type", str_t, 0, "The neural network type that should be used", "fcnn", edit_method=neural_network_type_enum)

group_yolo.add("yolo_model_path", str_t, 0, "Name of the yolo model", dummy_list[0], edit_method=yolo_paths_enum)

group_fcnn.add("fcnn_model_path", str_t, 0, "Name of the ball fcnn model", dummy_list[0], edit_method=fcnn_paths_enum)
group_fcnn.add("ball_fcnn_threshold", double_t, 0, "Minimal activation for a pixel in the fcnn heatmap to be considered", min=0.0, max=1.0)
group_fcnn.add("ball_fcnn_expand_stepsize", int_t, 0, "Expand stepsize for the ball fcnn clustering", min=1, max=20)
group_fcnn.add("ball_fcnn_pointcloud_stepsize", int_t, 0, "Pointcloud stepsize for the ball fcnn clustering", min=1, max=20)
group_fcnn.add("ball_fcnn_min_ball_diameter", int_t, 0, "Minimum diameter of a ball", min=1, max=50)
group_fcnn.add("ball_fcnn_max_ball_diameter", int_t, 0, "Maximum diameter of a ball", min=1, max=600)
group_fcnn.add("ball_fcnn_candidate_refinement_iteration_count", int_t, 0, "Number of iterations of refinement of ball candidates", min=1,max=100)
group_fcnn.add("ball_fcnn_publish_output", bool_t, 0, "Publish the output of the ball fcnn as ImageWithRegionOfInterest", None)
group_fcnn.add("ball_fcnn_publish_field_boundary_offset", int_t, 0, "The offset added to the field_boundary when cropping the fcnn output for publication in pixels", min=1,max=50)

group_neural_network_type.add("ball_candidate_field_boundary_y_offset", int_t, 0, "Threshold in which ball candidates over the field boundary are allowed.", min=0, max=800)
group_neural_network_type.add("ball_candidate_rating_threshold", double_t, 0, "A threshold for the minimum candidate rating", min=0.0, max=1.0)

group_field_color_detector.add("field_color_detector_path", str_t, 0, "Color space for the field color detector", dummy_list[0], edit_method=field_color_space_enum)

group_dynamic_color_space.add("dynamic_color_space_active", bool_t, 0, "Turn dynamic color space ON or OFF", None)
group_dynamic_color_space.add("dynamic_color_space_queue_max_size", int_t, 0, "Maximum size of queue that holds the latest added colors", min=1, max=100)
group_dynamic_color_space.add("dynamic_color_space_threshold", double_t, 0, "Necessary amount of previously detected color inside the kernel in percentage", min=0.0, max=1.0)
group_dynamic_color_space.add("dynamic_color_space_kernel_radius", int_t, 0, "Radius surrounding the center-element of kernel-matrix, defines relevant surrounding of pixel", min=1, max=100)
group_dynamic_color_space.add("dynamic_color_space_field_boundary_detector_search_method", str_t, 0, "Search method for FieldBoundaryFinder used by DynamicColorSpace", "reversed", edit_method=field_boundary_detector_enum)

group_white_color_detector.add("white_color_detector_lower_values_h", int_t, 0, "Lower bound for the white color detector hue", min=0, max=180)
group_white_color_detector.add("white_color_detector_lower_values_s", int_t, 0, "Lower bound for the white color detector saturation", min=0, max=255)
group_white_color_detector.add("white_color_detector_lower_values_v", int_t, 0, "Lower bound for the white color detector value/brightness", min=0, max=255)
group_white_color_detector.add("white_color_detector_upper_values_h", int_t, 0, "Upper bound for the white color detector hue", min=0, max=180)
group_white_color_detector.add("white_color_detector_upper_values_s", int_t, 0, "Upper bound for the white color detector saturation", min=0, max=255)
group_white_color_detector.add("white_color_detector_upper_values_v", int_t, 0, "Upper bound for the white color detector value/brightness", min=0, max=255)

group_red_color_detector.add("red_color_detector_lower_values_h", int_t, 0, "Lower bound for the red color detector hue", min=0, max=180)
group_red_color_detector.add("red_color_detector_lower_values_s", int_t, 0, "Lower bound for the red color detector saturation", min=0, max=255)
group_red_color_detector.add("red_color_detector_lower_values_v", int_t, 0, "Lower bound for the red color detector value/brightness", min=0, max=255)
group_red_color_detector.add("red_color_detector_upper_values_h", int_t, 0, "Upper bound for the red color detector hue", min=0, max=180)
group_red_color_detector.add("red_color_detector_upper_values_s", int_t, 0, "Upper bound for the red color detector saturation", min=0, max=255)
group_red_color_detector.add("red_color_detector_upper_values_v", int_t, 0, "Upper bound for the red color detector value/brightness", min=0, max=255)

group_blue_color_detector.add("blue_color_detector_lower_values_h", int_t, 0, "Lower bound for the blue color detector hue", min=0, max=180)
group_blue_color_detector.add("blue_color_detector_lower_values_s", int_t, 0, "Lower bound for the blue color detector saturation", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_lower_values_v", int_t, 0, "Lower bound for the blue color detector value/brightness", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_upper_values_h", int_t, 0, "Upper bound for the blue color detector hue", min=0, max=180)
group_blue_color_detector.add("blue_color_detector_upper_values_s", int_t, 0, "Upper bound for the blue color detector saturation", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_upper_values_v", int_t, 0, "Upper bound for the blue color detector value/brightness", min=0, max=255)

group_field_boundary_detector.add("field_boundary_detector_search_method", str_t, 0, "Method for finding the field boundary. E.g with scanlines from the bottom or the top.", "iteration", edit_method=field_boundary_detector_enum)
group_field_boundary_detector.add("field_boundary_detector_vertical_steps", int_t, 0, "Number of steps on each scanline", min=1, max=480)
group_field_boundary_detector.add("field_boundary_detector_horizontal_steps", int_t, 0, "Number of scanlines", min=1, max=640)
group_field_boundary_detector.add("field_boundary_detector_roi_height", int_t, 0, "Region Of Interest height in which we are looking for green", min=1, max=100)
group_field_boundary_detector.add("field_boundary_detector_roi_width", int_t, 0, "Region Of Interest width in which we are looking for green", min=1, max=100)
group_field_boundary_detector.add("field_boundary_detector_roi_increase", double_t, 0, "Value that increases the region of interest if it is located lower in the image", min=0, max=1.0)
group_field_boundary_detector.add("field_boundary_detector_green_threshold", int_t, 0, "Threshold of green in the area covered by the kernel", min=0, max=1000)
group_field_boundary_detector.add("field_boundary_detector_head_tilt_threshold", int_t, 0, "Threshold for the dynamic search method, that describes the head angle at which we are switching between the itaration and the reversed search method.", min=0, max=90)

group_line_detector.add("line_detector_field_boundary_offset", int_t, 0, "Theshold in which we are also searching for lines over the field boundary", min=0, max=200)
group_line_detector.add("line_detector_linepoints_range", int_t, 0, "Number of line points", min=0, max=20000)
group_line_detector.add("line_detector_use_line_points", bool_t, 0, "Calculate and publish the line points", None)
group_line_detector.add("line_detector_use_line_mask", bool_t, 0, "Calculate and publish the line mask", None)

group_obstacle_detector.add("obstacle_finder_method", str_t, 0, "Method for the obstacle finder", "convex", edit_method=obstacle_detector_enum)
group_obstacle_detector.add("obstacle_color_threshold", int_t, 0, "An obstacle is defined as blue/red if it contains more blue or red than this theshold", min=0, max=255)
group_obstacle_detector.add("obstacle_white_threshold", int_t, 0, "An obstacle that contains more white than this threshold and is not colored, is an goalpost in the conventional approach", min=0, max=255)
group_obstacle_detector.add("obstacle_field_boundary_diff_threshold", int_t, 0, "Minimal distance between detected and convex field boundary to accept it as obstacle", min=0, max=200)
group_obstacle_detector.add("obstacle_candidate_field_boundary_offset", int_t, 0, "Fixed height of obstacles above the field boundary", min=0, max=500)
group_obstacle_detector.add("obstacle_candidate_min_width", int_t, 0, "Minimum width of an obstacle", min=1, max=640)
group_obstacle_detector.add("obstacle_candidate_max_width", int_t, 0, "Maximum width of an obstacle", min=1, max=640)
group_obstacle_detector.add("obstacle_finder_step_length", int_t, 0, "Length of an object detection step along the field boundary", min=1, max=640)
group_obstacle_detector.add("obstacle_finder_value_increase", double_t, 0, "Factor of the impact of the height of the field boundary on the distance threshold", min=0, max=10.0)

group_debug.add("vision_publish_debug_image", bool_t, 0, "Publish debug image message", None)
group_debug.add("ball_fcnn_publish_debug_img", bool_t, 0, "Publish the fcnn heatmap image for debug purposes", None)
group_debug.add("vision_publish_HSV_mask_image", bool_t, 0, "Publish all three HSV color detector mask image mesages for debug purposes ", None)
group_debug.add("vision_publish_field_mask_image", bool_t, 0, "Publish field mask image message for debug purposes", None)

exit(gen.generate(PACKAGE, "bitbots_vision", "Vision"))
